# -*- coding: utf-8 -*-
"""Submission 1 - MLT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qak0qgl2A7YRhqureOrfGTj9Scc9VTaE

# **BTC Price Predictive Analytics**

Dataset: https://www.kaggle.com/sudalairajkumar/cryptocurrencypricehistory?select=coin_Bitcoin.csv

# Pendahuluan

Tema dari analisis ini adalah keuangan dimana hasilnya akan berupa model machine learning yang nanti dapat digunakan untuk memprediksi harga dari Bitcoin

# Data Loading
## Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import zipfile, math
import seaborn as sns
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn import metrics
from sklearn import preprocessing
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor

from google.colab import files

!pip install -q kaggle

uploaded = files.upload()

!chmod 600 /content/kaggle.json

! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d sudalairajkumar/cryptocurrencypricehistory

local_zip = '/content/cryptocurrencypricehistory.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

df = pd.read_csv('/content/coin_Bitcoin.csv')
df.sort_values(by=['Date'], inplace=True, ascending=True)
df.set_index('Date', inplace= True)
df

"""# Exploratory Data Analysis
## Deskripsi Variabel
*   Date : Tanggal pencatatan data
*   Open : harga ketika dibuka yang dihitung perhari
*   Close : harga ketika ditutup yang dihitung perhari
*   Low : harga terendah perhari
*   High : harga tertinggi perhari
*   Volume : volume transaksi perhari
*   Market Cap : Kapitalisasi Pasar berdasarkan USD
"""

df.info()

df.drop(['SNo', 'Name', 'Symbol', 'Volume','Marketcap'],axis=1,inplace=True)
df['OHLC_Average'] = (df['Open'] + df['High'] + df['Low'] + df['Close']) / 4
df

df.describe()

df.head()

df['Price_After_Month']=df['Close'].shift(-30)

df.tail()

"""## Menangani Missing Value dan Outlier

Output kode di atas memberikan informasi statistik pada masing-masing kolom, antara lain:

*   count adalah jumlah sampel pada data.
*   mean adalah nilai rata-rata.
*   std adalah standar deviasi.
*   min yaitu nilai minimum setiap kolom.
*   25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas *   *   interval dalam empat bagian sebaran yang sama.
*   50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
*   75% adalah kuartil ketiga.
*   Max adalah nilai maksimum
"""

df.isnull().sum()
#df.isna().sum()

"""Dari hasil prediksi diatas, tidak terdapat Missing Value pada setiap variabel"""

plt.subplots(figsize=(10,7))
sns.boxplot(data=df).set_title("Bitcoin")
plt.show()

"""Jika dilihat dari plot diatas terdapat banyak sekali Outlier pada setiap variabel yang dipilih"""

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3-Q1
df=df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]

df.shape

"""Untuk mengatasi Outlier diatas maka memerlukan penentuan batas atas dan bawah nilai quartil pada data

## Univariate Analysis

Karena tidak terdapat Categorical Features, maka kita dapat langsung menganalisis Numerical Features pada dataset dengan menampilkan plot dan grafik histogramnya
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""Dari hasil histogram diatas dapat disimpulkan bahwasannya hampir semua variabel Distribusi nilainya miring ke kanan (right-skewed). Hal ini akan berimplikasi pada model nantinya.

## Multivariate Analysis

Karena tidak terdapat Categorical Features, maka kita dapat langsung menganalisis Numerical Features pada dataset dengan menampilkan plot dan grafik relasinya
"""

sns.pairplot(df, diag_kind = 'kde')

"""Korelasi yang terjadi kebanyakan bernilai positif karena kebanyakan grafik pada sumbu y dan x mengalami peningkatan yang cukup signifikan membentuk sebuah garis"""

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""terlihat bahwa pada matriks korelasi diatas dapat disimpulkan bahwasannya semua variabel memiliki keterikatan dan korelasi yang kuat antar variabel lainnya, dimana nilai korelasi antar variabel bernilai lebih dari 0.9 atau mendekati 1.

## Data Preparation

### Train Test Split
"""

df.dropna(inplace=True)
X = df.drop('Price_After_Month',axis=1)

X = preprocessing.scale(X)
y = df['Price_After_Month']

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 100)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""### Standarisasi

Melakukan Standarisasi pada data Training dan Testing
"""

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

"""## Model Development"""

models = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""### K-Nearest Neighbor"""

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_train)

"""### Random Forest"""

RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""### Boosting Algorithm"""

boosting = AdaBoostRegressor(n_estimators=50, learning_rate=0.05, random_state=55)                             
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""## Evaluasi Model

### Mengukur seberapa kecil nilai error MSE
"""

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
 
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Dari gambar di atas, terlihat bahwa, model KNN memberikan nilai eror yang paling kecil. Model inilah yang dapat digunakan sebagai model terbaik untuk melakukan prediksi harga Bitcoin.

### Menghitung nilai akurasi model
"""

knn_accuracy = knn.score(X_test, y_test)*100
rf_accuracy = RF.score(X_test, y_test)*100
boosting_accuracy = boosting.score(X_test, y_test)*100

list_evaluasi = [[knn_accuracy],
            [rf_accuracy],
            [boosting_accuracy]]
evaluasi = pd.DataFrame(list_evaluasi,
                        columns=['Accuracy (%)'],
                        index=['K-Nearest Neighbor', 'Random Forest', 'Boosting'])
evaluasi

"""Dari hasil evaluasi di atas dapat memberikan informasi bahwa ketiga model yang dibangun memiliki performa di atas 80%. Dimana dapat dilihat juga bahwa model dengan algoritma KNN memiliki performa yang diukur dengan nilai akurasi yang lebih baik dari dua model lainnya yaitu model dengan algoritma Random Forest dan Boosting."""

X_30=X[-30:]
forecast=knn.predict(X_30)

df1=pd.DataFrame(forecast,columns=['Forecast'])
df1=df.append(df1)
df1.drop(['High', 'Low', 'Open'],axis=1,inplace=True)

df1.tail(35)

"""Berikut adalah nilai prediksi 30 hari kedepan yang didapat dari metode terbaik yaitu KNN yang dievaluasikan sebelumnya

## Penutup

Model untuk memprediksi harga bitcoin telah selesai dibuat dan dari hasil pengujian, ketiga model yang dibuat memiliki performa yang baik dan dapat digunakan untuk memprediksi data sebenarnya hanya saja model terbaik ialah model KNN karena KNN memiliki nilai akurasi yang tinggi dibandingkan dengan model lain.
"""